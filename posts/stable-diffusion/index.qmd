---
title: 'Stable Diffusion for dummies (written by a dummy)'
description: 'A little informal guide for diffusion first timers.'
author: 'Harsh Sharma'
date: '10/29/2023'
image: logo.png
categories:
  - Notes
  - Fastai Part2
---
# Stable Diffusion for dummies

Most people reading this have probably heard of image generation at some point in time. If you're among those who haven't, then this journey will be even better as I go in some fair detail to try and explain what it is.

If at any point, the things I talk about seem hard, don't be discouraged as it's more of a shock if you find this easy to read. Nevertheless, buckle up because although we might not go all the way into the deep-end (I don't know enough stuff yet), I think we'll still get to dip our toes.

![](buckleup.gif)

## Cool pics to pump you up:

\

I'll just let the images speak.  

\

![cozy warm image of an indian male programmer sitting near a beautiful pond, scenic, matches white background, beautiful](img3.jpg)

\

![Dune arakis in the background. Paul Atreides giving speech. Crowd listening is charged, ominous foreboding theme.](img4.jpg)

\

![inspiring landscape poster showing humanity as a multiplanetary species, sprawling metropolis with large structures, awe-inspiring, 1920x1080 image, outer space](img5.jpg)

\

All of the above were generated with simple but detailed text prompts.

::: {.callout-caution}
This blog and deep learning in general have the tendency to contain lots of technical jargon. It might be something stupidly simple once you actually learn what it is, but for some reason the DL community likes cool names I guess. In case you're a bit rusty with some of the terms, I've defined the most common ones below.
:::
::: {.callout-note collapse="true" title='Jargon'}
|Term | Meaning |
|-----|------------|
|parameters| the values in the model that change what task it can do, updated through model training|
| architecture | The mathematical function that we pass input data and parameters to |
|model | The combination of the architecture with a particular set of parameters|  
|gradient | A Tensor that tells us how the vector field changes in any direction |
| loss | A measure of how good the model is, chosen to drive training via stochastic gradient descent|
|CNN| Convolutional Neural Network; a type of NN that works well for computer vision tasks | 
| embeddings | A relatively-low dimension space into which we can translate high-dimensional vectors|
| latent | A latent is a compressed, rough representation of a higher quality image. It consists of the most important features of an image|
|noise| Random variation of brightness or color information in images|
:::

If you had to make a guess about how image generation works, what would that guess be? Think for a moment. If you're like me, then you probably thought that we try to get the model to spit out cool looking images, right? Well, not exactly. Bear with me for a moment.
\ 

Imagine a magic function that takes in images of handwritten digits as inputs and spits out the probability that the input is a digit. 
\ 

Let the probability be $P(X)$ for an input Image X.
```{mermaid}
flowchart LR
  I1(X1) --> F((Magic Function))
  I2(X2) --> F
  I3(X3) --> F
  F --> O1("P(X1)")
  F --> O2("P(X2)")
  F --> O3("P(X3)")

```

\

Wait. How do we use this function to generate new digits?\
We do the following steps:\

1. Try making a pixel of X darker and then check the output probability
2. Try making a pixel of X lighter and then check probability
3. Do this for every pixel in X (If X is a 28x28 image, that's 784 times!)

What we're calculating is the probability of X being a handwritten digit wrt the gradient of X. This function is called the `Score Funtion`.
$$\nabla_X P(X)$$

`Noisy image = Clear Image + Noise`\

Full disclaimer that this is an absurdly simplified explanation of it and the real thing is probably much more different and complicated but, it is a good place to build some intuition from.
\

Probability of Noise:





\

```{mermaid}
flowchart LR
    B["Randomly selected sequential noise"] -->  X((+))
    X --> A["Somewhat noisy latent"] --> C(("Diffusion Model"))
    C --> D("Predicted Noise") --> - --> A
    A --> E["Less noisy latent"]
    F["Randomly Selected Noise"] --> Z((+)) --> E -->
    G(("Updated Diffusion Model")) --> H("Predicted Noise")
    H --> Y[-] --> E
```

\

| Model             | Input                  | Output      | Notes              |
| ----------------- | ---------------------- | ----------- | ------------------ |
| Unet              | somewhat noisy latents | the noise   | -                  |
| VAE Decoder       | small latents tensor   | large image | guided by captions |
| CLIP text encoder | text                   | embedding   | -                  |
